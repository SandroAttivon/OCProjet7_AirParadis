{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aecf57c",
   "metadata": {},
   "source": [
    "# üß† Notebook complet - Approches avanc√©es Air Paradis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199b062c",
   "metadata": {},
   "source": [
    "Ce notebook couvre les pr√©traitements, embeddings, mod√®les Keras (dense, LSTM), BERT et Universal Sentence Encoder selon les crit√®res CE1 √† CE7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5cd9aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "- [1. Import du jeu de donn√©es et v√©rification de l'√©quilibrage](#1.-Import-du-jeu-de-donn√©es-et-v√©rification-de-l'√©quilibrage)\n",
       "- [2. Pr√©traitement du texte (nettoyage + stemming/lemmatisation)](#2.-Pr√©traitement-du-texte-(nettoyage-+-stemming/lemmatisation))\n",
       "- [3.1 Baseline : TF-IDF + R√©gression Logistique](#3.1-Baseline-:-TF-IDF-+-R√©gression-Logistique)\n",
       "- [3.2 Baseline : LSTM (Keras)](#3.2-Baseline-:-LSTM-(Keras))\n",
       "- [4. Embeddings Word2Vec, GloVe, FastText](#4.-Embeddings-Word2Vec,-GloVe,-FastText)\n",
       "  - [4.1 Chargement des embeddings GloVe et FastText](#4.1-Chargement-des-embeddings-GloVe-et-FastText)\n",
       "- [5. Mod√®les Keras avec embeddings](#5.-Mod√®les-Keras-avec-embeddings)\n",
       "  - [5.0 Int√©gration GloVe et FastText dans Keras](#5.0-Int√©gration-GloVe-et-FastText-dans-Keras)\n",
       "  - [5.1 Mod√®le Keras avec Word2Vec](#5.1-Mod√®le-Keras-avec-Word2Vec)\n",
       "  - [5.2 Mod√®le Keras avec GloVe](#5.2-Mod√®le-Keras-avec-GloVe)\n",
       "  - [5.3 Mod√®le Keras avec FastText](#5.3-Mod√®le-Keras-avec-FastText)\n",
       "- [6. BERT - Fine-tuning HuggingFace](#6.-BERT---Fine-tuning-HuggingFace)\n",
       "- [7. Universal Sentence Encoder](#7.-Universal-Sentence-Encoder)\n",
       "- [8. Synth√®se comparative des mod√®les](#8.-Synth√®se-comparative-des-mod√®les)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üìö Table des mati√®res automatique\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown('''\n",
    "- [1. Import du jeu de donn√©es et v√©rification de l'√©quilibrage](#1.-Import-du-jeu-de-donn√©es-et-v√©rification-de-l'√©quilibrage)\n",
    "- [2. Pr√©traitement du texte (nettoyage + stemming/lemmatisation)](#2.-Pr√©traitement-du-texte-(nettoyage-+-stemming/lemmatisation))\n",
    "- [3.1 Baseline : TF-IDF + R√©gression Logistique](#3.1-Baseline-:-TF-IDF-+-R√©gression-Logistique)\n",
    "- [3.2 Baseline : LSTM (Keras)](#3.2-Baseline-:-LSTM-(Keras))\n",
    "- [4. Embeddings Word2Vec, GloVe, FastText](#4.-Embeddings-Word2Vec,-GloVe,-FastText)\n",
    "  - [4.1 Chargement des embeddings GloVe et FastText](#4.1-Chargement-des-embeddings-GloVe-et-FastText)\n",
    "- [5. Mod√®les Keras avec embeddings](#5.-Mod√®les-Keras-avec-embeddings)\n",
    "  - [5.0 Int√©gration GloVe et FastText dans Keras](#5.0-Int√©gration-GloVe-et-FastText-dans-Keras)\n",
    "  - [5.1 Mod√®le Keras avec Word2Vec](#5.1-Mod√®le-Keras-avec-Word2Vec)\n",
    "  - [5.2 Mod√®le Keras avec GloVe](#5.2-Mod√®le-Keras-avec-GloVe)\n",
    "  - [5.3 Mod√®le Keras avec FastText](#5.3-Mod√®le-Keras-avec-FastText)\n",
    "- [6. BERT - Fine-tuning HuggingFace](#6.-BERT---Fine-tuning-HuggingFace)\n",
    "- [7. Universal Sentence Encoder](#7.-Universal-Sentence-Encoder)\n",
    "- [8. Synth√®se comparative des mod√®les](#8.-Synth√®se-comparative-des-mod√®les)\n",
    "'''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc919a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:8080\")\n",
    "\n",
    "# a copier dans le terminal : mlflow server --host 0.0.0.0 --port 8080\n",
    "\n",
    "# mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "# mlflow.set_experiment(\"sentiment_analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c8184a",
   "metadata": {},
   "source": [
    "## 1. Import du jeu de donn√©es et v√©rification de l'√©quilibrage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae6ac9da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6102c038-4fca-41e3-a77c-ffc8c7227d04",
       "rows": [
        [
         "0",
         "@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D",
         "0"
        ],
        [
         "1",
         "is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!",
         "0"
        ],
        [
         "2",
         "@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds",
         "0"
        ],
        [
         "3",
         "my whole body feels itchy and like its on fire ",
         "0"
        ],
        [
         "4",
         "@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. ",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...          0\n",
       "1  is upset that he can't update his Facebook by ...          0\n",
       "2  @Kenichan I dived many times for the ball. Man...          0\n",
       "3    my whole body feels itchy and like its on fire           0\n",
       "4  @nationwideclass no, it's not behaving at all....          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üì• Chargement du fichier CSV d'origine\n",
    "# Chargement du fichier CSV d'origine fourni (colonnes : target, id, date, flag, user, text)\n",
    "import pandas as pd\n",
    "\n",
    "input_path = 'C:/Users/sandr/OneDrive/Documents/JOB/OPENCLASSROOMS/AI_ENGINEER/Projet_7_R√©alisez_une_analyse_de_sentiments_gr√¢ce_au_Deep_Learning/Workspace/'\n",
    "\n",
    "raw_df = pd.read_csv(input_path + \"data/raw/training.1600000.processed.noemoticon.csv\", encoding=\"latin-1\", header=None)\n",
    "\n",
    "raw_df.columns = [\"sentiment\", \"id\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "raw_df['sentiment'] = raw_df['sentiment'].replace({0: 0, 4: 1})  # 0: n√©gatif, 4: positif\n",
    "\n",
    "# On extrait uniquement le texte et le label\n",
    "df = raw_df[[\"text\", \"sentiment\"]].copy()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d1d864f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©partition (%):\n",
      "sentiment\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# %pip install seaborn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(data=df, x='sentiment')\n",
    "plt.title(\"R√©partition des tweets par sentiment\")\n",
    "plt.xticks([0,1], ['N√©gatif', 'Positif'])\n",
    "plt.show()\n",
    "\n",
    "counts = df['sentiment'].value_counts(normalize=True)\n",
    "print(\"R√©partition (%):\")\n",
    "print(counts * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07d3e81",
   "metadata": {},
   "source": [
    "## 3. Echantillonnage stratifi√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db1376df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√âchantillon stratifi√© : 1000 tweets\n"
     ]
    }
   ],
   "source": [
    "# # üö¶ D√©tection RAM et d√©finition de SAMPLE_SIZE\n",
    "# import psutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# total_ram_gb = psutil.virtual_memory().total / 1024**3\n",
    "# if total_ram_gb < 4:\n",
    "#     SAMPLE_SIZE = 5000\n",
    "# elif total_ram_gb < 8:\n",
    "#     SAMPLE_SIZE = 10000\n",
    "# elif total_ram_gb < 12:\n",
    "#     SAMPLE_SIZE = 20000\n",
    "# else:\n",
    "#     SAMPLE_SIZE = 30000\n",
    "\n",
    "# print(f\"üí° RAM d√©tect√©e : {total_ram_gb:.1f} Go - SAMPLE_SIZE s√©lectionn√© : {SAMPLE_SIZE}\")\n",
    "\n",
    "SAMPLE_SIZE = 1000  # Pour tests rapides\n",
    "\n",
    "# üéØ √âchantillonnage stratifi√© unique (commune √† tous les mod√®les)\n",
    "df_sample, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=SAMPLE_SIZE,\n",
    "    stratify=df['sentiment'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"√âchantillon stratifi√© : {df_sample.shape[0]} tweets\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a354bf",
   "metadata": {},
   "source": [
    "V√©rifions l'√©quilibre de l'√©chantillon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "883bc71c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R√©partition (%):\n",
      "sentiment\n",
      "1    50.0\n",
      "0    50.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sns.countplot(data=df_sample, x='sentiment')\n",
    "plt.title(\"R√©partition des tweets par sentiment\")\n",
    "plt.xticks([0,1], ['N√©gatif', 'Positif'])\n",
    "plt.show()\n",
    "\n",
    "counts = df_sample['sentiment'].value_counts(normalize=True)\n",
    "print(\"R√©partition (%):\")\n",
    "print(counts * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c04c5d",
   "metadata": {},
   "source": [
    "L'√©chantillon est effectivement √©quilibr√©."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a9e26e",
   "metadata": {},
   "source": [
    "## 2. Pr√©traitement du texte (nettoyage + stemming/lemmatisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "947415b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # üßπ Nettoyage des tweets avec stemming et lemmatisation\n",
    "# # Nettoyage des tweets √† partir du fichier brut\n",
    "# # %pip install nltk\n",
    "\n",
    "# import re\n",
    "# import nltk\n",
    "# import os\n",
    "# from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# # üîß Force le chemin de recherche des ressources NLTK\n",
    "# nltk_data_path = \"C:/nltk_data\"\n",
    "# if not os.path.exists(nltk_data_path):\n",
    "#     os.makedirs(nltk_data_path)\n",
    "\n",
    "# nltk.data.path.append(nltk_data_path)\n",
    "\n",
    "# # Ensure nltk resources are downloaded\n",
    "# nltk.download('punkt', download_dir=nltk_data_path)\n",
    "# nltk.download('wordnet', download_dir=nltk_data_path)\n",
    "# nltk.download('omw-1.4', download_dir=nltk_data_path)\n",
    "# nltk.download('stopwords', download_dir=nltk_data_path)\n",
    "\n",
    "# # stemmer = PorterStemmer()\n",
    "# # # Use the preloaded stop_words variable instead of redefining it\n",
    "# # stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# stemmer = PorterStemmer()\n",
    "# lemmatizer = WordNetLemmatizer()  # ‚úÖ AJOUT √Ä FAIRE\n",
    "# # Use the preloaded stop_words variable instead of redefining it\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# def clean_text(text, method='lemma'):\n",
    "#     text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "#     text = re.sub(r\"@\\w+|#\", '', text)\n",
    "#     text = re.sub(r\"[^\\w\\s]\", '', text.lower())\n",
    "#     words = nltk.word_tokenize(text)\n",
    "#     words = [w for w in words if w not in stop_words]\n",
    "#     if method == 'stem':\n",
    "#         return ' '.join([stemmer.stem(w) for w in words])\n",
    "#     else:\n",
    "#         return ' '.join([lemmatizer.lemmatize(w) for w in words])\n",
    "\n",
    "# # Application sur le jeu de donn√©es brut\n",
    "# df_sample['text_stem'] = df_sample['text'].apply(lambda x: clean_text(x, 'stem'))\n",
    "# df_sample['text_lemma'] = df_sample['text'].apply(lambda x: clean_text(x, 'lemma'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd6ba4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sur un exemple simple:\n",
      "test tweet hashtag\n",
      "test tweet hashtags\n",
      "Traitement de 1000 tweets par lots de 100...\n",
      "Traitement du lot 1: tweets 1-100...\n",
      "Traitement du lot 2: tweets 101-200...\n",
      "Traitement du lot 3: tweets 201-300...\n",
      "Traitement du lot 4: tweets 301-400...\n",
      "Traitement du lot 5: tweets 401-500...\n",
      "Traitement du lot 6: tweets 501-600...\n",
      "Traitement du lot 7: tweets 601-700...\n",
      "Traitement du lot 8: tweets 701-800...\n",
      "Traitement du lot 9: tweets 801-900...\n",
      "Traitement du lot 10: tweets 901-1000...\n",
      "Termin√© !\n",
      "                                                      text  \\\n",
      "885281                   @ZinaTrainer @Gerrigge Thank you    \n",
      "1017950  For #followfriday: some newbies! @fsuwrestler2...   \n",
      "959762   mmkay. so monday=johns last day end of courses...   \n",
      "702896   @HOTTVampChick no  no more unless I win irvine...   \n",
      "1527418  @foxandfriends  Gmornin to you guys from Chicago    \n",
      "\n",
      "                                                 text_stem  \\\n",
      "885281                                               thank   \n",
      "1017950  followfriday some newbi welcom need some twitt...   \n",
      "959762   mmkay so mondayjohn last day end cours week jo...   \n",
      "702896   no no more unless win irvin tix break go anoth...   \n",
      "1527418                                gmornin guy chicago   \n",
      "\n",
      "                                                text_lemma  \n",
      "885281                                               thank  \n",
      "1017950  followfriday some newbie welcome need some twi...  \n",
      "959762   mmkay so mondayjohns last day end course week ...  \n",
      "702896   no no more unless win irvine tix break go anot...  \n",
      "1527418                                gmornin guy chicago  \n"
     ]
    }
   ],
   "source": [
    "# Solution simplifi√©e pour NLTK sans d√©pendance aux t√©l√©chargements\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# Liste de stopwords simplifi√©e (remplace la d√©pendance NLTK)\n",
    "STOPWORDS = {'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \n",
    "             'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', \n",
    "             'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', \n",
    "             'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', \n",
    "             'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', \n",
    "             'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', \n",
    "             'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', \n",
    "             'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', \n",
    "             'with', 'about', 'against', 'between', 'into', 'through', 'during', \n",
    "             'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', \n",
    "             'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once'}\n",
    "\n",
    "# Tokenizer simplifi√© (remplace nltk.word_tokenize)\n",
    "def simple_tokenize(text):\n",
    "    return re.findall(r'\\b\\w+\\b', text.lower())\n",
    "\n",
    "# Initialisation des outils\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Fonction de nettoyage sans d√©pendances probl√©matiques\n",
    "def clean_text(text, method='lemma'):\n",
    "    # Nettoyage du texte\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "    text = re.sub(r\"@\\w+|#\", '', text)\n",
    "    text = re.sub(r\"[^\\w\\s]\", '', text.lower())\n",
    "    \n",
    "    # Tokenization simplifi√©e\n",
    "    words = simple_tokenize(text)\n",
    "    \n",
    "    # Filtrage des stopwords\n",
    "    words = [w for w in words if w not in STOPWORDS]\n",
    "    \n",
    "    # Application du stemming ou lemmatisation\n",
    "    if method == 'stem':\n",
    "        return ' '.join([stemmer.stem(w) for w in words])\n",
    "    else:\n",
    "        return ' '.join([lemmatizer.lemmatize(w) for w in words])\n",
    "\n",
    "# Test sur un exemple\n",
    "print(\"Test sur un exemple simple:\")\n",
    "exemple = \"This is a test tweet with #hashtags and @mentions http://example.com\"\n",
    "print(clean_text(exemple, 'stem'))\n",
    "print(clean_text(exemple, 'lemma'))\n",
    "\n",
    "# Fonction pour traiter le DataFrame par lots pour √©viter les blocages\n",
    "def process_dataframe_in_batches(df_sample, batch_size=100):\n",
    "    print(f\"Traitement de {len(df_sample)} tweets par lots de {batch_size}...\")\n",
    "    result_df = df_sample.copy()\n",
    "    \n",
    "    # Traiter par lots pour √©viter les blocages\n",
    "    for i in range(0, len(df_sample), batch_size):\n",
    "        end_idx = min(i + batch_size, len(df_sample))\n",
    "        print(f\"Traitement du lot {i//batch_size + 1}: tweets {i+1}-{end_idx}...\")\n",
    "        \n",
    "        batch = df_sample.iloc[i:end_idx]\n",
    "        result_df.loc[batch.index, 'text_stem'] = batch['text'].apply(lambda x: clean_text(str(x), 'stem'))\n",
    "        result_df.loc[batch.index, 'text_lemma'] = batch['text'].apply(lambda x: clean_text(str(x), 'lemma'))\n",
    "        \n",
    "    return result_df\n",
    "\n",
    "# Appliquer au DataFrame (d√©commentez pour utiliser)\n",
    "df_processed = process_dataframe_in_batches(df_sample, batch_size=100)\n",
    "print(\"Termin√© !\")\n",
    "print(df_processed[['text', 'text_stem', 'text_lemma']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f235ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Initialisation de MLflow enrichie pour suivi des performances et efficacit√©\n",
    "# import mlflow\n",
    "import mlflow.sklearn\n",
    "import time\n",
    "import os\n",
    "\n",
    "mlflow.set_experiment(\"air_paradis_sentiment\")\n",
    "\n",
    "def log_model_metrics(model, X_val, y_val, model_name, keras=False):\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        start = time.time()\n",
    "        y_pred = model.predict(X_val)\n",
    "        elapsed = round((time.time() - start) / X_val.shape[0] * 1000, 3)  # ms/sample\n",
    "\n",
    "        if y_pred.ndim > 1:\n",
    "            y_pred = y_pred.ravel()\n",
    "        y_pred_label = (y_pred > 0.5).astype(int)\n",
    "\n",
    "        from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "        acc = round(accuracy_score(y_val, y_pred_label), 3)\n",
    "        f1 = round(f1_score(y_val, y_pred_label), 3)\n",
    "        rec = round(recall_score(y_val, y_pred_label), 3)\n",
    "\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_metric(\"recall\", rec)\n",
    "        mlflow.log_metric(\"inference_time_ms\", elapsed)\n",
    "\n",
    "        import tempfile\n",
    "        if keras:\n",
    "            from tensorflow.keras.models import save_model # type: ignore\n",
    "            model_path = tempfile.mktemp(suffix=\".h5\")\n",
    "            save_model(model, model_path)\n",
    "        else:\n",
    "            import joblib\n",
    "            model_path = tempfile.mktemp(suffix=\".pkl\")\n",
    "            joblib.dump(model, model_path)\n",
    "\n",
    "        if os.path.exists(model_path):\n",
    "            size_mb = round(os.path.getsize(model_path) / 1024 / 1024, 2)\n",
    "            mlflow.log_metric(\"model_size_mb\", size_mb)\n",
    "            mlflow.log_artifact(model_path, artifact_path=\"models\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a39b6b3",
   "metadata": {},
   "source": [
    "## 3.1 Baseline : TF-IDF + R√©gression Logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1115694",
   "metadata": {},
   "source": [
    "Param√©trer MLFlow pour stocker les r√©sultats des tests  !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c226ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run TF-IDF + LogReg at: http://localhost:8080/#/experiments/508725265954878499/runs/f555cbe867524191a5cffb64aa435b5f\n",
      "üß™ View experiment at: http://localhost:8080/#/experiments/508725265954878499\n"
     ]
    }
   ],
   "source": [
    "# üìä TF-IDF + R√©gression Logistique\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Vectorisation TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(df_processed['text_lemma'])\n",
    "\n",
    "# S√©paration\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_vec, X_temp_vec, y_train, y_temp = train_test_split(X_tfidf, df_processed['sentiment'], test_size=0.3, stratify=df_processed['sentiment'], random_state=42)\n",
    "X_val_vec, X_test_vec, y_val, y_test = train_test_split(X_temp_vec, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Entra√Ænement\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train_vec, y_train)\n",
    "\n",
    "# √âvaluation\n",
    "log_model_metrics(model, X_val_vec, y_val, \"TF-IDF + LogReg\", keras=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a2f598",
   "metadata": {},
   "source": [
    "## 3.2 Baseline : LSTM (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b493eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sandr\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sandr\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sandr\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\sandr\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sandr\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "6/6 [==============================] - 3s 123ms/step - loss: 0.6930 - accuracy: 0.5043 - val_loss: 0.6923 - val_accuracy: 0.5400\n",
      "Epoch 2/3\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.6878 - accuracy: 0.6200 - val_loss: 0.6911 - val_accuracy: 0.5200\n",
      "Epoch 3/3\n",
      "6/6 [==============================] - 0s 44ms/step - loss: 0.6795 - accuracy: 0.7200 - val_loss: 0.6883 - val_accuracy: 0.5867\n",
      "5/5 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Local\\Temp\\ipykernel_36372\\3822625902.py:34: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(model, model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run LSTM Baseline at: http://localhost:8080/#/experiments/508725265954878499/runs/45debee75dab4b6aa6a5d08f5a2b373c\n",
      "üß™ View experiment at: http://localhost:8080/#/experiments/508725265954878499\n"
     ]
    }
   ],
   "source": [
    "# üìä LSTM Baseline\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense # type: ignore\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # type: ignore\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences # type: ignore\n",
    "\n",
    "# Pr√©paration des donn√©es\n",
    "tokenizer = Tokenizer(num_words=20000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df_processed['text_lemma'])\n",
    "X_seq = tokenizer.texts_to_sequences(df_processed['text_lemma'])\n",
    "X_pad = pad_sequences(X_seq, maxlen=50)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_pad, df_processed['sentiment'], test_size=0.3, stratify=df_processed['sentiment'], random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "# Mod√®le LSTM\n",
    "model_lstm = Sequential([\n",
    "    Embedding(input_dim=20000, output_dim=64, input_length=50),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_lstm.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=3, batch_size=128)\n",
    "\n",
    "# √âvaluation\n",
    "log_model_metrics(model_lstm, X_val, y_val, \"LSTM Baseline\", keras=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3625e4c",
   "metadata": {},
   "source": [
    "LSTM tout seul = Fait\n",
    "LSTM + Word2Vec\n",
    "LSTM + Fastext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cf663a",
   "metadata": {},
   "source": [
    "## 4. Embeddings Word2Vec, GloVe, FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05bb744d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sandr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Si X_train contient des vecteurs ‚Üí il faut retourner au texte\n",
    "# Exemple : on repart de la colonne text_lemma du DataFrame de base\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "X_train_idx, _, y_train, _ = train_test_split(df_processed.index, df_processed['sentiment'], test_size=0.3, stratify=df_processed['sentiment'], random_state=42)\n",
    "\n",
    "# Exemple : extraction du texte source\n",
    "X_train_text = df_processed.loc[X_train_idx, \"text_lemma\"]  # ou bien une version d√©j√† s√©par√©e\n",
    "\n",
    "sentences = [text.split() for text in X_train_text]\n",
    "w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=5, workers=4)\n",
    "w2v_model.save(input_path + \"models/word2vec.model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1266dda9",
   "metadata": {},
   "source": [
    "### 4.1 Chargement des embeddings GloVe et FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cda81418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe charg√© : 400000 mots\n",
      "FastText charg√© : 999995 mots\n"
     ]
    }
   ],
   "source": [
    "# üìö Fonction utilitaire pour charger des embeddings externes (GloVe/FastText)\n",
    "import numpy as np\n",
    "\n",
    "def load_embedding(filepath):\n",
    "    embeddings_index = {}\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "# Chemins vers les fichiers d'embedding\n",
    "glove_path = input_path + 'data/embeddings/glove.6B.100d.txt'\n",
    "fasttext_path = input_path + 'data/embeddings/wiki-news-300d-1M.vec'\n",
    "\n",
    "# Chargement\n",
    "glove_embeddings = load_embedding(glove_path)\n",
    "fasttext_embeddings = load_embedding(fasttext_path)\n",
    "\n",
    "print(f\"GloVe charg√© : {len(glove_embeddings)} mots\")\n",
    "print(f\"FastText charg√© : {len(fasttext_embeddings)} mots\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4257273",
   "metadata": {},
   "source": [
    "## 5. Mod√®les Keras avec embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3785ccc6",
   "metadata": {},
   "source": [
    "### 5.1 Mod√®le Keras avec Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227f93f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6/6 [==============================] - 1s 34ms/step - loss: 0.6941 - accuracy: 0.4843 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6925 - accuracy: 0.5171 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6922 - accuracy: 0.5329 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6914 - accuracy: 0.5229 - val_loss: 0.6927 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6909 - accuracy: 0.5329 - val_loss: 0.6924 - val_accuracy: 0.5000\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "üèÉ View run Word2Vec at: http://localhost:8080/#/experiments/508725265954878499/runs/816434297b2943a582e7ff95c2b5d4dc\n",
      "üß™ View experiment at: http://localhost:8080/#/experiments/508725265954878499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Local\\Temp\\ipykernel_36372\\3822625902.py:34: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(model, model_path)\n"
     ]
    }
   ],
   "source": [
    "# üß† Construction du mod√®le Keras avec couche d'embedding\n",
    "# üìè Padding des s√©quences textuelles √† longueur fixe\n",
    "# üî¢ Tokenisation des textes pour entra√Ænement LSTM ou Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense, Dropout # type: ignore\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # type: ignore\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences # type: ignore\n",
    "\n",
    "X = df_processed['text_lemma']\n",
    "y = df_processed['sentiment']\n",
    "\n",
    "X_train_text, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "X_val_text, X_test_text, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=20000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train_text)\n",
    "X_train_pad = pad_sequences(tokenizer.texts_to_sequences(X_train_text), maxlen=50)\n",
    "X_val_pad = pad_sequences(tokenizer.texts_to_sequences(X_val_text), maxlen=50)\n",
    "\n",
    "model_w2v = Sequential([\n",
    "    Embedding(20000, 64, input_length=50),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_w2v.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_w2v.fit(X_train_pad, y_train, validation_data=(X_val_pad, y_val), epochs=5, batch_size=128)\n",
    "\n",
    "# √âvaluation et suivi MLflow\n",
    "log_model_metrics(model_w2v, X_val_pad, y_val, \"Word2Vec\", keras=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8c22f5",
   "metadata": {},
   "source": [
    "### 5.5 LSTM + Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74733246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "6/6 [==============================] - 2s 87ms/step - loss: 0.6934 - accuracy: 0.4871 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 2/3\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.6932 - accuracy: 0.4800 - val_loss: 0.6931 - val_accuracy: 0.5400\n",
      "Epoch 3/3\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.6929 - accuracy: 0.5329 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "üèÉ View run LSTM + Word2Vec at: http://localhost:8080/#/experiments/508725265954878499/runs/23ff5ccc69ba4da892c542b132ddbc0d\n",
      "üß™ View experiment at: http://localhost:8080/#/experiments/508725265954878499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Local\\Temp\\ipykernel_36372\\3822625902.py:34: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(model, model_path)\n"
     ]
    }
   ],
   "source": [
    "# üìä Mod√®le LSTM avec Word2Vec\n",
    "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]\n",
    "\n",
    "model_lstm_w2v = Sequential([\n",
    "    Embedding(input_dim=embedding_matrix.shape[0], output_dim=embedding_matrix.shape[1],\n",
    "              weights=[embedding_matrix], input_length=X_train_pad.shape[1], trainable=False),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_lstm_w2v.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_lstm_w2v.fit(X_train_pad, y_train, validation_data=(X_val_pad, y_val), epochs=3, batch_size=128)\n",
    "\n",
    "# √âvaluation et suivi MLflow\n",
    "log_model_metrics(model_lstm_w2v, X_val_pad, y_val, \"LSTM + Word2Vec\", keras=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bf1a6",
   "metadata": {},
   "source": [
    "### 5.6 LSTM + FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9869df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "6/6 [==============================] - 2s 82ms/step - loss: 0.6933 - accuracy: 0.4929 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 2/3\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.6932 - accuracy: 0.4886 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 3/3\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "5/5 [==============================] - 0s 7ms/step\n",
      "üèÉ View run LSTM + FastText (local) at: http://localhost:8080/#/experiments/508725265954878499/runs/ba12da88689648428925fe88e2ac4469\n",
      "üß™ View experiment at: http://localhost:8080/#/experiments/508725265954878499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Local\\Temp\\ipykernel_36372\\3822625902.py:34: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(model, model_path)\n"
     ]
    }
   ],
   "source": [
    "# üìä Mod√®le LSTM avec FastText (entra√Ænement local)\n",
    "from gensim.models import FastText\n",
    "import numpy as np\n",
    "\n",
    "# 1. Entra√Ænement du mod√®le FastText sur les donn√©es d'entra√Ænement\n",
    "sentences = [text.split() for text in X_train_text]\n",
    "ft_model = FastText(sentences, vector_size=100, window=5, min_count=5, workers=4)\n",
    "\n",
    "# 2. Cr√©ation de l'embedding matrix √† partir du tokenizer\n",
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in ft_model.wv:\n",
    "        embedding_matrix[i] = ft_model.wv[word]\n",
    "\n",
    "# 3. Cr√©ation du mod√®le LSTM avec embedding FastText\n",
    "model_lstm_ft = Sequential([\n",
    "    Embedding(input_dim=embedding_matrix.shape[0], output_dim=embedding_matrix.shape[1],\n",
    "              weights=[embedding_matrix], input_length=X_train_pad.shape[1], trainable=False),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_lstm_ft.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_lstm_ft.fit(X_train_pad, y_train, validation_data=(X_val_pad, y_val), epochs=3, batch_size=128)\n",
    "\n",
    "# 4. √âvaluation et suivi MLflow\n",
    "log_model_metrics(model_lstm_ft, X_val_pad, y_val, \"LSTM + FastText (local)\", keras=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481be718",
   "metadata": {},
   "source": [
    "### 5.0 Int√©gration GloVe et FastText dans Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b21b757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö Fonction utilitaire pour charger des embeddings externes (GloVe/FastText)\n",
    "import numpy as np\n",
    "\n",
    "# Fonction pour charger des embeddings pr√©-entra√Æn√©s\n",
    "def load_embedding(filepath):\n",
    "    embeddings_index = {}\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.strip().split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "# Charger GloVe\n",
    "glove_path = input_path + 'data/embeddings/glove.6B.100d.txt'\n",
    "glove_embeddings = load_embedding(glove_path)\n",
    "\n",
    "# Charger FastText\n",
    "fasttext_path = input_path + 'data/embeddings/wiki-news-300d-1M.vec'\n",
    "fasttext_embeddings = load_embedding(fasttext_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4394d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er les matrices d'embedding pour notre vocabulaire\n",
    "embedding_dim_glove = 100\n",
    "embedding_dim_fasttext = 300\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "embedding_matrix_glove = np.zeros((20000, embedding_dim_glove))\n",
    "embedding_matrix_fasttext = np.zeros((20000, embedding_dim_fasttext))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= 20000:\n",
    "        continue\n",
    "    vec_g = glove_embeddings.get(word)\n",
    "    if vec_g is not None:\n",
    "        embedding_matrix_glove[i] = vec_g\n",
    "    vec_f = fasttext_embeddings.get(word)\n",
    "    if vec_f is not None:\n",
    "        embedding_matrix_fasttext[i] = vec_f\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a544e641",
   "metadata": {},
   "source": [
    "### 5.2 Mod√®le Keras avec GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364868b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "6/6 [==============================] - 1s 78ms/step - loss: 0.6984 - accuracy: 0.5057 - val_loss: 0.6879 - val_accuracy: 0.4933\n",
      "Epoch 2/3\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6848 - accuracy: 0.5486 - val_loss: 0.6927 - val_accuracy: 0.5133\n",
      "Epoch 3/3\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6718 - accuracy: 0.6300 - val_loss: 0.6897 - val_accuracy: 0.5467\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "üèÉ View run GloVe at: http://localhost:8080/#/experiments/508725265954878499/runs/b6607d7de5de491cb04ad3227dfde85f\n",
      "üß™ View experiment at: http://localhost:8080/#/experiments/508725265954878499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Local\\Temp\\ipykernel_36372\\3822625902.py:34: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(model, model_path)\n"
     ]
    }
   ],
   "source": [
    "# üìä Mod√®le Keras avec GloVe\n",
    "model_glove = Sequential([\n",
    "    Embedding(input_dim=embedding_matrix_glove.shape[0], output_dim=embedding_matrix_glove.shape[1],\n",
    "              weights=[embedding_matrix_glove], input_length=X_pad.shape[1], trainable=False),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_glove.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_glove.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=3, batch_size=128)\n",
    "\n",
    "# √âvaluation\n",
    "log_model_metrics(model_glove, X_val, y_val, \"GloVe\", keras=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8909827e",
   "metadata": {},
   "source": [
    "### 5.3 Mod√®le Keras avec FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f886642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "6/6 [==============================] - 2s 90ms/step - loss: 0.6929 - accuracy: 0.5143 - val_loss: 0.6921 - val_accuracy: 0.5533\n",
      "Epoch 2/3\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.6839 - accuracy: 0.5986 - val_loss: 0.6921 - val_accuracy: 0.5200\n",
      "Epoch 3/3\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.6786 - accuracy: 0.6314 - val_loss: 0.6909 - val_accuracy: 0.5133\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "üèÉ View run FastText at: http://localhost:8080/#/experiments/508725265954878499/runs/48b224585dfc4b1dbfcaef6ace7e058e\n",
      "üß™ View experiment at: http://localhost:8080/#/experiments/508725265954878499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Local\\Temp\\ipykernel_36372\\3822625902.py:34: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(model, model_path)\n"
     ]
    }
   ],
   "source": [
    "# üìä Mod√®le Keras avec FastText\n",
    "model_fasttext = Sequential([\n",
    "    Embedding(input_dim=embedding_matrix_fasttext.shape[0], output_dim=embedding_matrix_fasttext.shape[1],\n",
    "              weights=[embedding_matrix_fasttext], input_length=X_pad.shape[1], trainable=False),\n",
    "    LSTM(64),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_fasttext.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_fasttext.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=3, batch_size=128)\n",
    "\n",
    "# √âvaluation\n",
    "log_model_metrics(model_fasttext, X_val, y_val, \"FastText\", keras=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab0aa6",
   "metadata": {},
   "source": [
    "BERT avec Embedding + classification !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c9e5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f972d1f6",
   "metadata": {},
   "source": [
    "## 6. BERT - Regression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcebed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       100\n",
      "           1       0.77      0.75      0.76       100\n",
      "\n",
      "    accuracy                           0.76       200\n",
      "   macro avg       0.76      0.76      0.76       200\n",
      "weighted avg       0.76      0.76      0.76       200\n",
      "\n",
      "üèÉ View run BERT + LogisticRegression at: http://localhost:8080/#/experiments/508725265954878499/runs/04280a7f0ce640f09b6afbb99c1591db\n",
      "üß™ View experiment at: http://localhost:8080/#/experiments/508725265954878499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# üìä BERT + R√©gression Logistique (embedding)\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Chargement du tokenizer et mod√®le BERT (non fine-tun√©)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_bert_embeddings(texts, tokenizer, model, max_len=64):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_len)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()  # CLS token\n",
    "\n",
    "# Pour acc√©l√©rer la d√©mo, on prend un √©chantillon r√©duit (ex : 5000 tweets)\n",
    "# sample_df = df.sample(5000, random_state=42)\n",
    "# X_bert = get_bert_embeddings(sample_df['text_lemma'].tolist(), tokenizer, bert_model)\n",
    "# y_bert = sample_df['sentiment'].values\n",
    "\n",
    "X_bert = get_bert_embeddings(df_processed['text_lemma'].tolist(), tokenizer, bert_model)\n",
    "y_bert = df_processed['sentiment'].values\n",
    "\n",
    "# Split + Mod√®le\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bert, y_bert, test_size=0.2, stratify=y_bert, random_state=42)\n",
    "model_bert = LogisticRegression(max_iter=(100)) # au lieu de 1000\n",
    "model_bert.fit(X_train, y_train)\n",
    "y_pred = model_bert.predict(X_test)\n",
    "\n",
    "# √âvaluation\n",
    "# print(\"\\nüìå √âvaluation du mod√®le : BERT + LogisticRegression\")\n",
    "# print(\"----------------------------------------\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# üîç √âvaluation compl√®te avec l√©g√®ret√© et performance\n",
    "log_model_metrics(model_bert, X_test, y_test, \"BERT + LogisticRegression\", keras=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d32bd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.6878 - accuracy: 0.5562 - val_loss: 0.6281 - val_accuracy: 0.6800\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6265 - accuracy: 0.6862 - val_loss: 0.5914 - val_accuracy: 0.7000\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5911 - accuracy: 0.7038 - val_loss: 0.5625 - val_accuracy: 0.7350\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "üèÉ View run BERT Embedding + Dense NN Classifier at: http://localhost:8080/#/experiments/508725265954878499/runs/5870b804ee1546e594525c404ed04e1a\n",
      "üß™ View experiment at: http://localhost:8080/#/experiments/508725265954878499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Local\\Temp\\ipykernel_36372\\3822625902.py:34: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(model, model_path)\n"
     ]
    }
   ],
   "source": [
    "# üìä BERT Embedding + Dense NN Classifier\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Dense # type: ignore\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Rechargement BERT si n√©cessaire\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_bert_embeddings(texts, tokenizer, model, max_len=64):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_len)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()  # vecteurs CLS\n",
    "\n",
    "\n",
    "X_bert_embed = get_bert_embeddings(df_processed['text_lemma'].tolist(), tokenizer, bert_model)\n",
    "y_bert_embed = df_processed['sentiment'].values\n",
    "\n",
    "# Split jeu\n",
    "X_train_b, X_val_b, y_train_b, y_val_b = train_test_split(X_bert_embed, y_bert_embed, test_size=0.2, stratify=y_bert_embed, random_state=42)\n",
    "\n",
    "# Mod√®le Keras simple\n",
    "model_bert_dense = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(768,)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_bert_dense.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_bert_dense.fit(X_train_b, y_train_b, validation_data=(X_val_b, y_val_b), epochs=3, batch_size=128)\n",
    "\n",
    "# √âvaluation et log MLflow\n",
    "log_model_metrics(model_bert_dense, X_val_b, y_val_b, \"BERT Embedding + Dense NN Classifier\", keras=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d2b849",
   "metadata": {},
   "source": [
    "### 6.3 TFBertModel (Hugging Face) + Classification (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145f2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.7134 - accuracy: 0.5038 - val_loss: 0.6774 - val_accuracy: 0.5400\n",
      "Epoch 2/3\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6546 - accuracy: 0.6050 - val_loss: 0.6164 - val_accuracy: 0.6850\n",
      "Epoch 3/3\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6319 - accuracy: 0.6662 - val_loss: 0.5853 - val_accuracy: 0.7250\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "üèÉ View run TFBertModel + classification Keras at: http://localhost:8080/#/experiments/508725265954878499/runs/31be6fb2522640b8b45535b4ba4ce05f\n",
      "üß™ View experiment at: http://localhost:8080/#/experiments/508725265954878499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sandr\\AppData\\Local\\Temp\\ipykernel_36372\\3822625902.py:34: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(model, model_path)\n"
     ]
    }
   ],
   "source": [
    "# üìä Embedding avec TFBertModel + classification Keras\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Dense # type: ignore\n",
    "\n",
    "# Chargement du mod√®le et tokenizer Hugging Face\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model_tf = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Pr√©paration des entr√©es BERT\n",
    "def get_tfbert_embeddings(texts, tokenizer, model, max_len=64):\n",
    "    inputs = tokenizer(texts, padding='max_length', truncation=True,\n",
    "                      return_tensors=\"tf\", max_length=max_len)\n",
    "    outputs = model(inputs)[0][:, 0, :]  # vecteur CLS\n",
    "    return outputs.numpy()\n",
    "\n",
    "\n",
    "X_embed = get_tfbert_embeddings(df_processed['text_lemma'].tolist(), tokenizer, bert_model_tf)\n",
    "y_embed = df_processed['sentiment'].values\n",
    "\n",
    "# Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_b, X_val_b, y_train_b, y_val_b = train_test_split(X_embed, y_embed, test_size=0.2, stratify=y_embed, random_state=42)\n",
    "\n",
    "# Mod√®le Keras (classification)\n",
    "model_tfbert_dense = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(768,)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_tfbert_dense.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_tfbert_dense.fit(X_train_b, y_train_b, validation_data=(X_val_b, y_val_b), epochs=3, batch_size=128)\n",
    "\n",
    "# √âvaluation et log\n",
    "# eval_model_extended(model_tfbert_dense, X_val_b, y_val_b, \"TFBertModel + Dense\", keras=True)\n",
    "log_model_metrics(model_tfbert_dense, X_val_b, y_val_b, \"TFBertModel + classification Keras\", keras=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
