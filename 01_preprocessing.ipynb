{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e89cb889",
   "metadata": {},
   "source": [
    "# ðŸ§¹ 01 - PrÃ©traitement des tweets\n",
    "Ce notebook a pour objectif de charger, nettoyer et sauvegarder un sous-ensemble des tweets en vue de l'entraÃ®nement des modÃ¨les."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba441f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ada417a",
   "metadata": {},
   "source": [
    "## ðŸ“¥ Chargement des donnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71260c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/training.1600000.processed.noemoticon.csv\", encoding=\"ISO-8859-1\", header=None)\n",
    "df.columns = ['sentiment', 'id', 'date', 'query', 'user', 'text']\n",
    "df['sentiment'] = df['sentiment'].map({0: 0, 4: 1})  # 0 = nÃ©gatif, 1 = positif\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1355f969",
   "metadata": {},
   "source": [
    "## ðŸ“Š RÃ©partition des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a052ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x='sentiment')\n",
    "plt.title(\"RÃ©partition des tweets par sentiment\")\n",
    "plt.xticks([0,1], ['NÃ©gatif', 'Positif'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289c5676",
   "metadata": {},
   "source": [
    "## ðŸ§¹ Nettoyage des textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # liens\n",
    "    text = re.sub(r'\\@\\w+|\\#','', text)  # mentions & hashtags\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # ponctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # chiffres\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # espaces\n",
    "    return text\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text).apply(remove_stopwords)\n",
    "df[['text', 'clean_text']].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c153ef",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Sauvegarde dâ€™un sous-ensemble Ã©quilibrÃ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb62a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = (\n",
    "    df.groupby(\"sentiment\")\n",
    "      .apply(lambda x: x.sample(n=50000, random_state=42))\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "df_balanced.to_csv(\"../data/processed/tweets_clean.csv\", index=False)\n",
    "print(\"âœ… DonnÃ©es nettoyÃ©es et enregistrÃ©es dans data/processed/tweets_clean.csv\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}